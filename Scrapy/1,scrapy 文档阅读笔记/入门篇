
Now, after extracting the data, the parse() method looks for the link to
the next page, builds a full absolute URL using the urljoin() method
(since the links can be relative) and yields a new request to the next page
>>>next_page = response.css('li.next a::attr(href)').get()
>>>        if next_page is not None:
>>>            next_page = response.urljoin(next_page)
>>>            yield scrapy.Request(next_page, callback=self.parse)
As a shortcut for creating Request objects you can use response.follow:
>>>next_page = response.css('li.next a::attr(href)').get()
>>>        if next_page is not None:
>>>            yield response.follow(next_page, callback=self.parse)
Unlike scrapy.Request, response.follow supports relative URLs directly
- no need to call urljoin. Note that response.follow just returns a Request instance; you still have to yield this Request.
You can also pass a selector to response.follow instead of a string;
this selector should extract necessary attributes:
>>>for href in response.css('li.next a::attr(href)'):
>>>    yield response.follow(href, callback=self.parse)
For <a> elements there is a shortcut: response.follow uses their href attribute automatically.
So the code can be shortened further:
>>>for a in response.css('li.next a'):
>>>    yield response.follow(a, callback=self.parse)


[默认情况下，Scrapy会过滤重复访问的url]
By default, Scrapy filters out duplicated requests to URLs already visited,
avoiding the problem of hitting servers too much because of a programming mistake.
This can be configured by the setting DUPEFILTER_CLASS.


You can provide command line arguments to your spiders by using the -a option when running them:
>>>scrapy crawl quotes -o quotes-humor.json -a tag=humor
In this example, the value provided for the tag argument will be available via self.tag.
You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:
>>>def start_requests(self):
>>>        url = 'http://quotes.toscrape.com/'
>>>        tag = getattr(self, 'tag', None)
>>>        if tag is not None:
>>>            url = url + 'tag/' + tag
>>>        yield scrapy.Request(url, self.parse)


